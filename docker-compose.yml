services:
  # ==============================================================================
  # SSL Certificate Generator
  # Generates self-signed JKS certs for internal Kafka mTLS communication
  # ==============================================================================
  generate-kafka-ssl:
    image: eclipse-temurin:11-jre
    container_name: generate_kafka_ssl
    volumes:
      - ./certs:/certs
    environment:
      - KAFKA_SSL_KEYSTORE_PASSWORD=${KAFKA_SSL_KEYSTORE_PASSWORD:-changeit}
      - KAFKA_SSL_TRUSTSTORE_PASSWORD=${KAFKA_SSL_TRUSTSTORE_PASSWORD:-changeit}
      - KAFKA_SSL_KEY_PASSWORD=${KAFKA_SSL_KEY_PASSWORD:-changeit}
    command:
      - bash
      - -c
      - |
        echo "==== Checking for existing Kafka certificates ====";
        if [ -f "/certs/kafka.server.keystore.jks" ]; then
          echo "Kafka certificates already exist, skipping generation";
        else
          echo "==== Generating Kafka SSL Certificates ====";

          cd /certs;

          echo "Generating CA certificate...";
          keytool -genkeypair \
            -alias ca \
            -keyalg RSA \
            -keysize 2048 \
            -validity 365 \
            -keystore ca.keystore.jks \
            -storepass ${KAFKA_SSL_KEYSTORE_PASSWORD} \
            -keypass ${KAFKA_SSL_KEY_PASSWORD} \
            -dname "CN=Kafka-CA, OU=DevOps, O=YourOrg, L=Tehran, ST=Tehran, C=IR" \
            -ext bc=ca:true;

          keytool -exportcert \
            -alias ca \
            -keystore ca.keystore.jks \
            -storepass ${KAFKA_SSL_KEYSTORE_PASSWORD} \
            -file kafka-ca.crt \
            -rfc;

          echo "Generating Kafka broker keystore...";
          keytool -genkeypair \
            -alias kafka \
            -keyalg RSA \
            -keysize 2048 \
            -validity 365 \
            -keystore kafka.server.keystore.jks \
            -storepass ${KAFKA_SSL_KEYSTORE_PASSWORD} \
            -keypass ${KAFKA_SSL_KEY_PASSWORD} \
            -dname "CN=kafka, OU=DevOps, O=YourOrg, L=Tehran, ST=Tehran, C=IR" \
            -ext SAN=DNS:kafka,DNS:kafka-kraft,DNS:localhost,IP:127.0.0.1;

          keytool -certreq \
            -alias kafka \
            -keystore kafka.server.keystore.jks \
            -storepass ${KAFKA_SSL_KEYSTORE_PASSWORD} \
            -keypass ${KAFKA_SSL_KEY_PASSWORD} \
            -file kafka.csr;

          keytool -gencert \
            -alias ca \
            -keystore ca.keystore.jks \
            -storepass ${KAFKA_SSL_KEYSTORE_PASSWORD} \
            -infile kafka.csr \
            -outfile kafka-signed.crt \
            -ext SAN=DNS:kafka,DNS:kafka-kraft,DNS:localhost,IP:127.0.0.1 \
            -validity 365;

          keytool -importcert \
            -alias ca \
            -file kafka-ca.crt \
            -keystore kafka.server.keystore.jks \
            -storepass ${KAFKA_SSL_KEYSTORE_PASSWORD} \
            -keypass ${KAFKA_SSL_KEY_PASSWORD} \
            -noprompt;

          keytool -importcert \
            -alias kafka \
            -file kafka-signed.crt \
            -keystore kafka.server.keystore.jks \
            -storepass ${KAFKA_SSL_KEYSTORE_PASSWORD} \
            -keypass ${KAFKA_SSL_KEY_PASSWORD} \
            -noprompt;

          echo "Generating Kafka truststore...";
          keytool -importcert \
            -alias ca \
            -file kafka-ca.crt \
            -keystore kafka.server.truststore.jks \
            -storepass ${KAFKA_SSL_TRUSTSTORE_PASSWORD} \
            -noprompt;

          echo "Generating Kafka client keystore...";
          keytool -genkeypair \
            -alias kafka-client \
            -keyalg RSA \
            -keysize 2048 \
            -validity 365 \
            -keystore kafka.client.keystore.jks \
            -storepass ${KAFKA_SSL_KEYSTORE_PASSWORD} \
            -keypass ${KAFKA_SSL_KEY_PASSWORD} \
            -dname "CN=kafka-client, OU=DevOps, O=YourOrg, L=Tehran, ST=Tehran, C=IR";

          keytool -certreq \
            -alias kafka-client \
            -keystore kafka.client.keystore.jks \
            -storepass ${KAFKA_SSL_KEYSTORE_PASSWORD} \
            -keypass ${KAFKA_SSL_KEY_PASSWORD} \
            -file kafka-client.csr;

          keytool -gencert \
            -alias ca \
            -keystore ca.keystore.jks \
            -storepass ${KAFKA_SSL_KEYSTORE_PASSWORD} \
            -infile kafka-client.csr \
            -outfile kafka-client-signed.crt \
            -validity 365;

          keytool -importcert \
            -alias ca \
            -file kafka-ca.crt \
            -keystore kafka.client.keystore.jks \
            -storepass ${KAFKA_SSL_KEYSTORE_PASSWORD} \
            -keypass ${KAFKA_SSL_KEY_PASSWORD} \
            -noprompt;

          keytool -importcert \
            -alias kafka-client \
            -file kafka-client-signed.crt \
            -keystore kafka.client.keystore.jks \
            -storepass ${KAFKA_SSL_KEYSTORE_PASSWORD} \
            -keypass ${KAFKA_SSL_KEY_PASSWORD} \
            -noprompt;

          keytool -importcert \
            -alias ca \
            -file kafka-ca.crt \
            -keystore kafka.client.truststore.jks \
            -storepass ${KAFKA_SSL_TRUSTSTORE_PASSWORD} \
            -noprompt;

          keytool -importkeystore \
            -srckeystore kafka.client.keystore.jks \
            -destkeystore kafka.client.keystore.p12 \
            -srcstoretype JKS \
            -deststoretype PKCS12 \
            -srcstorepass ${KAFKA_SSL_KEYSTORE_PASSWORD} \
            -deststorepass ${KAFKA_SSL_KEYSTORE_PASSWORD} \
            -noprompt;

          openssl pkcs12 -in kafka.client.keystore.p12 -nokeys -out kafka-client.crt

          echo "Creating credentials files...";
          echo "${KAFKA_SSL_KEYSTORE_PASSWORD}" > keystore_creds;
          echo "${KAFKA_SSL_KEY_PASSWORD}" > key_creds;
          echo "${KAFKA_SSL_TRUSTSTORE_PASSWORD}" > truststore_creds;

          chmod 644 *.jks *.crt *_creds;
          chmod 600 *.key 2>/dev/null || true;

          rm -f *.csr ca.keystore.jks *-signed.crt;

          echo "Kafka SSL certificates generated successfully";
          ls -la /certs/;
        fi
    networks:
      - kafka-platform

  # ==============================================================================
  # Kafka Broker — Confluent Community Edition
  # KRaft mode (no ZooKeeper), SSL for internal + external listeners
  # ==============================================================================
  kafka:
    image: confluentinc/cp-kafka:${KAFKA_VERSION:-8.0.0}
    container_name: kafka-kraft
    hostname: kafka
    restart: unless-stopped

    depends_on:
      generate-kafka-ssl:
        condition: service_completed_successfully

    ports:
      - "9095:9095"
    expose:
      - "9091"
      - "9092"

    environment:
      # ----- KRaft -----
      KAFKA_NODE_ID: "${KAFKA_NODE_ID:-1}"
      KAFKA_PROCESS_ROLES: "broker,controller"
      CLUSTER_ID: "${KAFKA_CLUSTER_ID:-EmptNWtoR4GGWx-BH6nGLQ}"

      # ----- Controller -----
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"

      # ----- Listeners -----
      KAFKA_LISTENERS: "SSL://kafka:9091,CONTROLLER://kafka:9093,HOST://0.0.0.0:9092,EXTERNAL://0.0.0.0:9095"
      KAFKA_ADVERTISED_LISTENERS: "SSL://kafka:9091,HOST://${KAFKA_ADVERTISED_HOST:-localhost}:9092,EXTERNAL://${KAFKA_ADVERTISED_HOST:-localhost}:9095"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,SSL:SSL,HOST:PLAINTEXT,EXTERNAL:SSL"
      KAFKA_INTER_BROKER_LISTENER_NAME: "SSL"

      # ----- SSL -----
      KAFKA_SSL_KEYSTORE_FILENAME: "kafka.server.keystore.jks"
      KAFKA_SSL_KEYSTORE_LOCATION: "/etc/kafka/secrets/kafka.server.keystore.jks"
      KAFKA_SSL_KEYSTORE_CREDENTIALS: "keystore_creds"
      KAFKA_SSL_KEYSTORE_PASSWORD: "${KAFKA_SSL_KEYSTORE_PASSWORD:-changeit}"
      KAFKA_SSL_KEY_CREDENTIALS: "key_creds"
      KAFKA_SSL_KEY_PASSWORD: "${KAFKA_SSL_KEY_PASSWORD:-changeit}"
      KAFKA_SSL_TRUSTSTORE_FILENAME: "kafka.server.truststore.jks"
      KAFKA_SSL_TRUSTSTORE_LOCATION: "/etc/kafka/secrets/kafka.server.truststore.jks"
      KAFKA_SSL_TRUSTSTORE_PASSWORD: "${KAFKA_SSL_TRUSTSTORE_PASSWORD:-changeit}"
      KAFKA_SSL_TRUSTSTORE_CREDENTIALS: "truststore_creds"
      KAFKA_SSL_CLIENT_AUTH: "none"
      KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: ""

      # ----- Replication -----
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "${KAFKA_REPLICATION_FACTOR:-1}"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "${KAFKA_REPLICATION_FACTOR:-1}"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "${KAFKA_MIN_ISR:-1}"
      KAFKA_DEFAULT_REPLICATION_FACTOR: "${KAFKA_REPLICATION_FACTOR:-1}"
      KAFKA_MIN_INSYNC_REPLICAS: "${KAFKA_MIN_ISR:-1}"

      # ----- Performance -----
      KAFKA_HEAP_OPTS: "${KAFKA_HEAP_OPTS:--Xmx1G -Xms1G}"
      KAFKA_NUM_NETWORK_THREADS: "${KAFKA_NETWORK_THREADS:-3}"
      KAFKA_NUM_IO_THREADS: "${KAFKA_IO_THREADS:-8}"
      KAFKA_SOCKET_SEND_BUFFER_BYTES: "102400"
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: "102400"
      KAFKA_SOCKET_REQUEST_MAX_BYTES: "104857600"

      # ----- Retention -----
      KAFKA_LOG_RETENTION_HOURS: "${KAFKA_LOG_RETENTION_HOURS:-168}"
      KAFKA_LOG_RETENTION_BYTES: "${KAFKA_LOG_RETENTION_BYTES:-1073741824}"
      KAFKA_LOG_SEGMENT_BYTES: "1073741824"
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: "300000"
      KAFKA_LOG_FLUSH_INTERVAL_MESSAGES: "10000"
      KAFKA_LOG_FLUSH_INTERVAL_MS: "1000"

      # ----- Misc -----
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "${KAFKA_AUTO_CREATE_TOPICS:-true}"
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: "0"
      KAFKA_COMPRESSION_TYPE: "${KAFKA_COMPRESSION_TYPE:-producer}"
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: "false"

      # ----- Logging -----
      KAFKA_LOG4J_ROOT_LOGLEVEL: "${KAFKA_LOG_LEVEL:-INFO}"
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"

    volumes:
      - kafka-data:/var/lib/kafka/data
      - ./certs:/etc/kafka/secrets:ro

    healthcheck:
      test:
        [
          "CMD-SHELL",
          "kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

    deploy:
      resources:
        limits:
          memory: ${KAFKA_MEMORY_LIMIT:-2G}
          cpus: "${KAFKA_CPU_LIMIT:-2.0}"
        reservations:
          memory: ${KAFKA_MEMORY_RESERVATION:-1G}
          cpus: "${KAFKA_CPU_RESERVATION:-1.0}"

    networks:
      - kafka-platform

  # ==============================================================================
  # Schema Registry — Confluent Community Edition
  # Central schema store for Avro / Protobuf / JSON Schema
  # ==============================================================================
  schema-registry:
    image: confluentinc/cp-schema-registry:${KAFKA_VERSION:-8.0.0}
    container_name: schema-registry
    hostname: schema-registry
    restart: unless-stopped

    depends_on:
      kafka:
        condition: service_healthy

    expose:
      - "8081"

    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka:9091"
      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8081"

      # ----- SSL to Kafka -----
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: "SSL"
      SCHEMA_REGISTRY_KAFKASTORE_SSL_TRUSTSTORE_LOCATION: "/etc/kafka/secrets/kafka.client.truststore.jks"
      SCHEMA_REGISTRY_KAFKASTORE_SSL_TRUSTSTORE_PASSWORD: "${KAFKA_SSL_TRUSTSTORE_PASSWORD:-changeit}"
      SCHEMA_REGISTRY_KAFKASTORE_SSL_KEYSTORE_LOCATION: "/etc/kafka/secrets/kafka.client.keystore.jks"
      SCHEMA_REGISTRY_KAFKASTORE_SSL_KEYSTORE_PASSWORD: "${KAFKA_SSL_KEYSTORE_PASSWORD:-changeit}"
      SCHEMA_REGISTRY_KAFKASTORE_SSL_KEY_PASSWORD: "${KAFKA_SSL_KEY_PASSWORD:-changeit}"
      SCHEMA_REGISTRY_KAFKASTORE_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: ""

    volumes:
      - ./certs:/etc/kafka/secrets:ro

    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081/subjects || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    deploy:
      resources:
        limits:
          memory: ${SCHEMA_REGISTRY_MEMORY_LIMIT:-512M}
          cpus: "${SCHEMA_REGISTRY_CPU_LIMIT:-0.5}"
        reservations:
          memory: ${SCHEMA_REGISTRY_MEMORY_RESERVATION:-256M}
          cpus: "${SCHEMA_REGISTRY_CPU_RESERVATION:-0.25}"

    networks:
      - kafka-platform

  # ==============================================================================
  # Kafka Connect — Confluent (cp-server-connect-datagen)
  # Includes Datagen connector for generating synthetic test data
  # ==============================================================================
  kafka-connect:
    image: cnfldemos/cp-server-connect-datagen:0.6.4-7.6.0
    container_name: kafka-connect
    hostname: kafka-connect
    restart: unless-stopped

    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy

    expose:
      - "8083"

    environment:
      # ----- Bootstrap -----
      CONNECT_BOOTSTRAP_SERVERS: "kafka:9091"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_REST_PORT: "8083"

      # ----- Group -----
      CONNECT_GROUP_ID: "compose-connect-group"

      # ----- Internal Topics -----
      CONNECT_CONFIG_STORAGE_TOPIC: "docker-connect-configs"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: "10000"
      CONNECT_OFFSET_STORAGE_TOPIC: "docker-connect-offsets"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_TOPIC: "docker-connect-status"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"

      # ----- Converters -----
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "io.confluent.connect.avro.AvroConverter"
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"

      # ----- SSL to Kafka -----
      CONNECT_SECURITY_PROTOCOL: "SSL"
      CONNECT_SSL_TRUSTSTORE_LOCATION: "/etc/kafka/secrets/kafka.client.truststore.jks"
      CONNECT_SSL_TRUSTSTORE_PASSWORD: "${KAFKA_SSL_TRUSTSTORE_PASSWORD:-changeit}"
      CONNECT_SSL_KEYSTORE_LOCATION: "/etc/kafka/secrets/kafka.client.keystore.jks"
      CONNECT_SSL_KEYSTORE_PASSWORD: "${KAFKA_SSL_KEYSTORE_PASSWORD:-changeit}"
      CONNECT_SSL_KEY_PASSWORD: "${KAFKA_SSL_KEY_PASSWORD:-changeit}"
      CONNECT_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: ""

      # ----- Producer SSL -----
      CONNECT_PRODUCER_SECURITY_PROTOCOL: "SSL"
      CONNECT_PRODUCER_SSL_TRUSTSTORE_LOCATION: "/etc/kafka/secrets/kafka.client.truststore.jks"
      CONNECT_PRODUCER_SSL_TRUSTSTORE_PASSWORD: "${KAFKA_SSL_TRUSTSTORE_PASSWORD:-changeit}"
      CONNECT_PRODUCER_SSL_KEYSTORE_LOCATION: "/etc/kafka/secrets/kafka.client.keystore.jks"
      CONNECT_PRODUCER_SSL_KEYSTORE_PASSWORD: "${KAFKA_SSL_KEYSTORE_PASSWORD:-changeit}"
      CONNECT_PRODUCER_SSL_KEY_PASSWORD: "${KAFKA_SSL_KEY_PASSWORD:-changeit}"
      CONNECT_PRODUCER_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: ""

      # ----- Consumer SSL -----
      CONNECT_CONSUMER_SECURITY_PROTOCOL: "SSL"
      CONNECT_CONSUMER_SSL_TRUSTSTORE_LOCATION: "/etc/kafka/secrets/kafka.client.truststore.jks"
      CONNECT_CONSUMER_SSL_TRUSTSTORE_PASSWORD: "${KAFKA_SSL_TRUSTSTORE_PASSWORD:-changeit}"
      CONNECT_CONSUMER_SSL_KEYSTORE_LOCATION: "/etc/kafka/secrets/kafka.client.keystore.jks"
      CONNECT_CONSUMER_SSL_KEYSTORE_PASSWORD: "${KAFKA_SSL_KEYSTORE_PASSWORD:-changeit}"
      CONNECT_CONSUMER_SSL_KEY_PASSWORD: "${KAFKA_SSL_KEY_PASSWORD:-changeit}"
      CONNECT_CONSUMER_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: ""

      # ----- Plugin Path -----
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"

      # ----- Logging -----
      CONNECT_LOG4J_ROOT_LOGLEVEL: "WARN"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=ERROR,org.reflections=ERROR,org.apache.kafka.clients=ERROR"
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %m (%c)%n"

    volumes:
      - kafka-connect-data:/data
      - kafka-connect-plugins:/usr/share/confluent-hub-components
      - ./certs:/etc/kafka/secrets:ro

    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8083/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 180s

    deploy:
      resources:
        limits:
          memory: ${KAFKA_CONNECT_MEMORY_LIMIT:-2G}
          cpus: "${KAFKA_CONNECT_CPU_LIMIT:-1.0}"
        reservations:
          memory: ${KAFKA_CONNECT_MEMORY_RESERVATION:-1G}
          cpus: "${KAFKA_CONNECT_CPU_RESERVATION:-0.5}"

    networks:
      - kafka-platform

  # ==============================================================================
  # Kafka REST Proxy — Confluent Community Edition
  # HTTP interface for producing/consuming messages without a native Kafka client
  # ==============================================================================
  rest-proxy:
    image: confluentinc/cp-kafka-rest:${KAFKA_VERSION:-8.0.0}
    container_name: rest-proxy
    hostname: rest-proxy
    restart: unless-stopped

    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy

    expose:
      - "8082"

    environment:
      KAFKA_REST_HOST_NAME: rest-proxy
      KAFKA_REST_BOOTSTRAP_SERVERS: "kafka:9091"
      KAFKA_REST_LISTENERS: "http://0.0.0.0:8082"
      KAFKA_REST_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"

      # ----- SSL to Kafka -----
      KAFKA_REST_CLIENT_SECURITY_PROTOCOL: "SSL"
      KAFKA_REST_CLIENT_SSL_TRUSTSTORE_LOCATION: "/etc/kafka/secrets/kafka.client.truststore.jks"
      KAFKA_REST_CLIENT_SSL_TRUSTSTORE_PASSWORD: "${KAFKA_SSL_TRUSTSTORE_PASSWORD:-changeit}"
      KAFKA_REST_CLIENT_SSL_KEYSTORE_LOCATION: "/etc/kafka/secrets/kafka.client.keystore.jks"
      KAFKA_REST_CLIENT_SSL_KEYSTORE_PASSWORD: "${KAFKA_SSL_KEYSTORE_PASSWORD:-changeit}"
      KAFKA_REST_CLIENT_SSL_KEY_PASSWORD: "${KAFKA_SSL_KEY_PASSWORD:-changeit}"
      KAFKA_REST_CLIENT_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: ""

    volumes:
      - ./certs:/etc/kafka/secrets:ro

    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8082/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    deploy:
      resources:
        limits:
          memory: ${REST_PROXY_MEMORY_LIMIT:-512M}
          cpus: "${REST_PROXY_CPU_LIMIT:-0.5}"
        reservations:
          memory: ${REST_PROXY_MEMORY_RESERVATION:-256M}
          cpus: "${REST_PROXY_CPU_RESERVATION:-0.25}"

    networks:
      - kafka-platform

  # ==============================================================================
  # ksqlDB Server — Confluent Community Edition
  # SQL engine for stream processing directly on Kafka topics
  # Disabled: remove comment blocks below to enable
  # ==============================================================================
  # ksqldb-server:
  #   image: confluentinc/cp-ksqldb-server:${KAFKA_VERSION:-8.0.0}
  #   container_name: ksqldb-server
  #   hostname: ksqldb-server
  #   restart: unless-stopped
  #   depends_on:
  #     kafka:
  #       condition: service_healthy
  #     kafka-connect:
  #       condition: service_healthy
  #   ports:
  #     - "8088:8088"
  #   environment:
  #     KSQL_CONFIG_DIR: "/etc/ksql"
  #     KSQL_BOOTSTRAP_SERVERS: "kafka:9091"
  #     KSQL_HOST_NAME: ksqldb-server
  #     KSQL_LISTENERS: "http://0.0.0.0:8088"
  #     KSQL_CACHE_MAX_BYTES_BUFFERING: 0
  #     KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
  #     KSQL_KSQL_CONNECT_URL: "http://kafka-connect:8083"
  #     KSQL_KSQL_LOGGING_PROCESSING_TOPIC_REPLICATION_FACTOR: 1
  #     KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
  #     KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
  #     KSQL_SECURITY_PROTOCOL: "SSL"
  #     KSQL_SSL_TRUSTSTORE_LOCATION: "/etc/kafka/secrets/kafka.client.truststore.jks"
  #     KSQL_SSL_TRUSTSTORE_PASSWORD: "${KAFKA_SSL_TRUSTSTORE_PASSWORD:-changeit}"
  #     KSQL_SSL_KEYSTORE_LOCATION: "/etc/kafka/secrets/kafka.client.keystore.jks"
  #     KSQL_SSL_KEYSTORE_PASSWORD: "${KAFKA_SSL_KEYSTORE_PASSWORD:-changeit}"
  #     KSQL_SSL_KEY_PASSWORD: "${KAFKA_SSL_KEY_PASSWORD:-changeit}"
  #     KSQL_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: ""
  #   volumes:
  #     - ./certs:/etc/kafka/secrets:ro
  #   networks:
  #     - kafka-platform

  # ksqldb-cli:
  #   image: confluentinc/cp-ksqldb-cli:${KAFKA_VERSION:-8.0.0}
  #   container_name: ksqldb-cli
  #   depends_on:
  #     - ksqldb-server
  #   entrypoint: /bin/sh
  #   tty: true
  #   networks:
  #     - kafka-platform

  # ==============================================================================
  # Flink JobManager — Confluent-flavored Apache Flink
  # Coordinates distributed stream processing jobs, hosts the Web UI
  # ==============================================================================
  flink-jobmanager:
    image: cnfldemos/flink-kafka:1.19.1-scala_2.12-java17
    container_name: flink-jobmanager
    hostname: flink-jobmanager
    restart: unless-stopped

    command: jobmanager

    expose:
      - "6123"
      - "9081"

    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        rest.bind-port: 9081
        jobmanager.memory.process.size: ${FLINK_JM_MEMORY:-1600m}
        parallelism.default: ${FLINK_PARALLELISM:-1}

    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9081/overview || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    deploy:
      resources:
        limits:
          memory: ${FLINK_JM_MEMORY_LIMIT:-2G}
          cpus: "${FLINK_JM_CPU_LIMIT:-1.0}"
        reservations:
          memory: ${FLINK_JM_MEMORY_RESERVATION:-1G}
          cpus: "${FLINK_JM_CPU_RESERVATION:-0.5}"

    networks:
      - kafka-platform

  # ==============================================================================
  # Flink TaskManager — Confluent-flavored Apache Flink
  # Executes the actual stream processing tasks assigned by JobManager
  # ==============================================================================
  flink-taskmanager:
    image: cnfldemos/flink-kafka:1.19.1-scala_2.12-java17
    container_name: flink-taskmanager
    hostname: flink-taskmanager
    restart: unless-stopped

    depends_on:
      flink-jobmanager:
        condition: service_healthy

    command: taskmanager

    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: ${FLINK_TASK_SLOTS:-10}
        taskmanager.memory.process.size: ${FLINK_TM_MEMORY:-1728m}

    deploy:
      resources:
        limits:
          memory: ${FLINK_TM_MEMORY_LIMIT:-2G}
          cpus: "${FLINK_TM_CPU_LIMIT:-2.0}"
        reservations:
          memory: ${FLINK_TM_MEMORY_RESERVATION:-1G}
          cpus: "${FLINK_TM_CPU_RESERVATION:-1.0}"

    networks:
      - kafka-platform

  # ==============================================================================
  # Flink SQL Client — Interactive SQL shell connected to JobManager
  # Attach with: docker exec -it flink-sql-client ./bin/sql-client.sh
  # ==============================================================================
  flink-sql-client:
    image: cnfldemos/flink-sql-client-kafka:1.19.1-scala_2.12-java17
    container_name: flink-sql-client
    hostname: flink-sql-client

    depends_on:
      flink-jobmanager:
        condition: service_healthy

    environment:
      FLINK_JOBMANAGER_HOST: flink-jobmanager

    networks:
      - kafka-platform

  # ==============================================================================
  # Kafka UI — provectuslabs/kafka-ui
  # Web UI for topics, consumer groups, connectors, schema registry, and Flink
  # Accessible via: https://kafka-ui.yourdomain.com
  # ==============================================================================
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    hostname: kafka-ui
    restart: unless-stopped

    depends_on:
      kafka:
        condition: service_healthy
      kafka-connect:
        condition: service_healthy
      schema-registry:
        condition: service_healthy

    expose:
      - "8080"

    environment:
      DYNAMIC_CONFIG_ENABLED: "true"
      KAFKA_CLUSTERS_0_NAME: "${KAFKA_UI_CLUSTER_NAME:-kafka-platform}"
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: "kafka:9091"

      # ----- SSL to Kafka -----
      KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL: "SSL"
      KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_LOCATION: "/etc/kafka/secrets/kafka.client.truststore.jks"
      KAFKA_CLUSTERS_0_PROPERTIES_SSL_TRUSTSTORE_PASSWORD: "${KAFKA_SSL_TRUSTSTORE_PASSWORD:-changeit}"

      # ----- Schema Registry -----
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: "http://schema-registry:8081"

      # ----- Kafka Connect -----
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: "kafka-connect"
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: "http://kafka-connect:8083"

      # ----- UI Settings -----
      KAFKA_CLUSTERS_0_READONLY: "${KAFKA_UI_READONLY:-false}"
      KAFKA_CLUSTERS_0_AUDIT_TOPICAUDITENABLED: "true"
      KAFKA_CLUSTERS_0_AUDIT_CONSOLEAUDITENABLED: "true"

      # ----- Authentication -----
      AUTH_TYPE: "LOGIN_FORM"
      SPRING_SECURITY_USER_NAME: "${KAFKA_UI_USERNAME:-admin}"
      SPRING_SECURITY_USER_PASSWORD: "${KAFKA_UI_PASSWORD:-admin123}"

      # ----- Performance -----
      SERVER_MAX_HTTP_REQUEST_SIZE: "20MB"

    volumes:
      - ./certs:/etc/kafka/secrets:ro

    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --no-verbose --tries=1 --spider http://localhost:8080/actuator/health || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
        reservations:
          memory: 256M
          cpus: "0.25"

    networks:
      - kafka-platform

  # ==============================================================================
  # Nginx Reverse Proxy
  # Terminates TLS with real Let's Encrypt certificates from ./cert/
  # All services are internal-only; only Nginx is exposed on 80/443
  #
  # DNS A records required (all pointing to this server's IP):
  #   kafka-ui.yourdomain.com        -> kafka-ui:8080
  #   flink.yourdomain.com           -> flink-jobmanager:9081
  #   schema-registry.yourdomain.com -> schema-registry:8081
  #   kafka-connect.yourdomain.com   -> kafka-connect:8083
  #   rest-proxy.yourdomain.com      -> rest-proxy:8082
  # ==============================================================================
  nginx:
    image: nginx:alpine
    container_name: nginx
    hostname: nginx
    restart: unless-stopped

    depends_on:
      - kafka-ui
      - flink-jobmanager
      - schema-registry
      - kafka-connect
      - rest-proxy

    ports:
      - "80:80"
      - "443:443"

    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/auth/.htpasswd:/etc/nginx/auth/.htpasswd:ro
      - ./certs/fullchain.pem:/etc/nginx/ssl/fullchain.pem:ro
      - ./certs/privkey.pem:/etc/nginx/ssl/privkey.pem:ro

    healthcheck:
      test: ["CMD-SHELL", "nginx -t || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

    deploy:
      resources:
        limits:
          memory: 128M
          cpus: "0.25"
        reservations:
          memory: 64M
          cpus: "0.1"

    networks:
      - kafka-platform

# ==============================================================================
# Networks
# ==============================================================================
networks:
  kafka-platform:
    driver: bridge
    name: kafka-platform

# ==============================================================================
# Volumes
# ==============================================================================
volumes:
  kafka-data:
    driver: local
    name: kafka-data
  kafka-connect-data:
    driver: local
    name: kafka-connect-data
  kafka-connect-plugins:
    driver: local
    name: kafka-connect-plugins
